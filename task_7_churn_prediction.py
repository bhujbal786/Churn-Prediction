# -*- coding: utf-8 -*-
"""Task 7 : Churn Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EvxIFNFaz7DuxsZBAcsO2y8BXoQ82kXz
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from google.colab import files

# Prompt the user to select the uploaded file
uploaded = files.upload()

# Get the file name
filename = list(uploaded.keys())[0]

# Load the CSV file into a Pandas DataFrame
import pandas as pd
df = pd.read_csv(filename)

# Display the DataFrame
df.head()

plt.style.use('fivethirtyeight')

df.columns

from sklearn.model_selection import train_test_split

train_df, test_df = train_test_split(df, test_size=0.2, random_state=0)

train_df

test_df

print(f'The base has {df.shape[0]} rows and {df.shape[1]} columns.')

df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
train_df['TotalCharges'] = pd.to_numeric(train_df['TotalCharges'], errors='coerce')
test_df['TotalCharges'] = pd.to_numeric(test_df['TotalCharges'], errors='coerce')

df.info()

df.isna().sum()

df.dropna(axis = 0, inplace=True)
 train_df.dropna(axis = 0, inplace=True)
 test_df.dropna(axis = 0, inplace=True)

print(f'There are {df.duplicated().sum()} duplicates in the base.')

df.describe()

left_df = df[df['Churn'] == 'Yes']
stayed_df = df[df['Churn'] == 'No']

print('Total = ', len(df))
print('Number of customers leaving the service = ', len(left_df))
print('Percentage of customers leaving the service = ', (len(left_df) / len(df)) * 100)
print('Number of customers who continued with the service = ', len(stayed_df))
print('Percentage of customers who continued with the service = ', (len(stayed_df) / len(df)) * 100)

df.hist(bins=30, figsize=(20,10))

plt.figure(figsize=(16, 9))
sns.countplot(data = df, x = 'gender')
plt.title('Total by gender')
plt.xlabel('Gender')
plt.ylabel('Total')

df_gender = df['gender'].value_counts(1).reset_index()
df_gender = df_gender.rename({'index': 'gender', 'gender': '%'}, axis=1)
df_gender

plt.figure(figsize=(16, 9))
sns.countplot(data = df, x = 'Partner')
plt.title('Total by partners')
plt.xlabel('Partners')
plt.ylabel('Total')

df_partner = df['Partner'].value_counts(1).reset_index()
df_partner = df_partner.rename({'index': 'parceiros', 'Partner': '%'}, axis=1)
df_partner

fig, axes = plt.subplots(2, 2, figsize=(16, 9))
_ = sns.countplot(data = df, x = 'PhoneService', ax=axes[0][0])
_ = sns.countplot(data = df, x = 'InternetService', ax=axes[0][1])
_ = sns.countplot(data = df, x = 'StreamingTV', ax=axes[1][0])
_ = sns.countplot(data = df, x = 'StreamingMovies', ax=axes[1][1])

plt.figure(figsize=(16, 9))
sns.countplot(data = df, x = 'PaymentMethod')
plt.title('Total per payment method')
plt.xlabel('Payment method')
plt.ylabel('Total')

df_payment_method = df['PaymentMethod'].value_counts(1).reset_index()
df_payment_method = df_payment_method.rename({'index': 'payment_method', 'PaymentMethod': '%'}, axis=1)
df_payment_method

plt.figure(figsize=(16, 9))
sns.countplot(data = df, x = 'Contract')
plt.title('Total per contract type')
plt.xlabel('Type of contract')
plt.ylabel('Total')

df_contract = df['Contract'].value_counts(1).reset_index()
df_contract = df_contract.rename({'index': 'contract', 'Contract': '%'}, axis=1)
df_contract

df2 = df[['PaymentMethod', 'Contract', 'Churn']]
df2

plt.figure(figsize=(16, 9))
sns.countplot(data=df2, x="PaymentMethod", hue="Churn")
plt.title('Total by payment method grouped by churn')
plt.xlabel('Payment method')
plt.ylabel('Total')

plt.figure(figsize=(16, 9))
sns.countplot(data=df2, x="PaymentMethod", hue="Contract")
plt.title('Total per payment method')
plt.xlabel('Payment method')
plt.ylabel('Total')

plt.figure(figsize=(16, 9))
sns.countplot(data=df2, x="Contract", hue="Churn")
plt.title('Total by contract type grouped by churn')
plt.xlabel('Type of contract')
plt.ylabel('Total')

df3 = df[['MonthlyCharges', 'TotalCharges', 'Churn']]
df3

plt.figure(figsize=(16, 9))
sns.kdeplot(data=df3, x="MonthlyCharges", hue='Churn', multiple="stack")
plt.title('Density by monthly payment grouped by churn')
plt.xlabel('Monthly payment')
plt.ylabel('Density')

plt.figure(figsize=(16, 9))
sns.kdeplot(data=df3, x="TotalCharges", hue='Churn', multiple="stack")
plt.title('Density per total payment grouped by churn')
plt.xlabel('Total payment')
plt.ylabel('Density')

df4 = df[['tenure', 'Churn']]
df4

plt.figure(figsize=(25, 9))
sns.countplot(data=df4, x="tenure", hue='Churn')
plt.title('Total by usage time grouped by churn')
plt.xlabel('Usage time')
plt.ylabel('Total')

train_df.drop('customerID', axis = 1, inplace = True)
test_df.drop('customerID', axis = 1, inplace = True)

train_df['Churn'] = train_df['Churn'].map({"Yes": 1, "No": 0})
test_df['Churn'] = test_df['Churn'].map({"Yes": 1, "No": 0})

s = train_df.dtypes == 'object'
object_cols = list(s[s].index)

print('Categorical variables: ')
print(object_cols)

from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(handle_unknown = 'ignore', sparse=False)
cat_train_df = pd.DataFrame(encoder.fit_transform(train_df[object_cols]))
cat_test_df = pd.DataFrame(encoder.fit_transform(test_df[object_cols]))

cat_train_df.index = train_df.index
cat_test_df.index = test_df.index

num_train_df = train_df.drop(object_cols, axis = 1)
num_test_df = test_df.drop(object_cols, axis = 1)

encoded_df_train = pd.concat([num_train_df, cat_train_df], axis=1)
encoded_df_test = pd.concat([num_test_df, cat_test_df], axis=1)

encoded_df_train.columns = encoded_df_train.columns.astype(str)
encoded_df_test.columns = encoded_df_test.columns.astype(str)

encoded_df_train

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

X = encoded_df_train.drop('Churn', axis=1)
y = encoded_df_train['Churn']

X = scaler.fit_transform(X)

print(X, y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

print(X_train.shape, X_test.shape)

print(y_train.shape, y_test.shape)

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

def validation(test, predicted):
  acc = accuracy_score(test, predicted)
  cm = confusion_matrix(test, predicted)
  cr = classification_report(test, predicted)

  print(f'The accuracy of the model was {acc}')
  print(cr)
  sns.heatmap(cm, annot=True, fmt=',d')

from sklearn.linear_model import LogisticRegression

logistic = LogisticRegression()
logistic.fit(X_train, y_train)

y_pred_logistic = logistic.predict(X_test)

validation(y_test, y_pred_logistic)

from sklearn.ensemble import RandomForestClassifier

forest = RandomForestClassifier()
forest = forest.fit(X_train, y_train)
y_pred_forest = forest.predict(X_test)

validation(y_test, y_pred_forest)

from sklearn.tree import DecisionTreeClassifier

decision_tree = DecisionTreeClassifier()
decision_tree = decision_tree.fit(X_train, y_train)
y_pred_tree = decision_tree.predict(X_test)

validation(y_test, y_pred_tree)

from sklearn.naive_bayes import GaussianNB

naive_bayes = GaussianNB()
naive_bayes = naive_bayes.fit(X_train, y_train)
y_pred_naive = naive_bayes.predict(X_test)

validation(y_test, y_pred_naive)

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=3)
knn = knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)

validation(y_test, y_pred_knn)

X = encoded_df_test.drop('Churn', axis=1)
y = encoded_df_test['Churn']

X = scaler.fit_transform(X)

print(X, y)

y_new_pred = naive_bayes.predict(X)

validation(y, y_new_pred)

